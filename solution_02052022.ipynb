{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, tqdm, json, pickle, gc, zipfile, itertools, time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dateutil import parser\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from collections import defaultdict\n",
    "from multiprocessing import Pool\n",
    "import catboost as cb\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit, cross_val_score, ParameterGrid, StratifiedKFold, cross_val_predict\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "from tqdm.contrib.concurrent import process_map  \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import shap \n",
    "from sklearn.model_selection import KFold\n",
    "from nancorrmp.nancorrmp import NaNCorrMp\n",
    "# from pathos.multiprocessing import ProcessingPool as Pool\n",
    "import multiprocessing as mp\n",
    "\n",
    "class CatBoostOptimizer():\n",
    "    \n",
    "    def __init__(self, scoring_func, const_params, seed, direction, n_trials):\n",
    "        self.scoring_func = scoring_func        \n",
    "        self.const_params = const_params\n",
    "        self.seed = seed\n",
    "        self.direction = direction\n",
    "        self.n_trials = n_trials\n",
    "\n",
    "    def objective(self, trial):\n",
    "                \n",
    "        params = {\n",
    "#         'iterations':trial.suggest_int('iterations', 20, 500),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.025, 0.25),\n",
    "        'depth': trial.suggest_int('depth', 3, 12),\n",
    "        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1, 31),\n",
    "        'boosting_type': trial.suggest_categorical('boosting_type', ['Ordered', 'Plain']),\n",
    "                }\n",
    "        \n",
    "        params.update(self.const_params)\n",
    "                \n",
    "        model = cb.CatBoostClassifier(**params, random_seed=self.seed)\n",
    "        model.fit(self.X_tr_c, self.y_tr_c, verbose=0, eval_set=(self.X_ho_c, self.y_ho_c))\n",
    "        \n",
    "        y_proba = model.predict_proba(self.X_ho_c)[:, 1]\n",
    "        \n",
    "        return self.scoring_func(self.y_ho_c, y_proba)\n",
    "    \n",
    "    def fit(self, X_tr, y_tr):\n",
    "        \n",
    "        self.cat_features = np.argwhere(X_tr.dtypes.values=='object').flatten()\n",
    "        \n",
    "        self.X_tr_c, self.X_ho_c, self.y_tr_c, self.y_ho_c = \\\n",
    "            train_test_split(X_tr, y_tr,\n",
    "                             test_size = .1,\n",
    "                             shuffle = True,\n",
    "                             random_state =self.seed)\n",
    "        \n",
    "        sampler = TPESampler(seed=self.seed)\n",
    "        study = optuna.create_study(direction=self.direction, sampler=sampler)\n",
    "        study.optimize(self.objective, n_trials=self.n_trials)\n",
    "        self.best_params = study.best_params\n",
    "        \n",
    "        del self.X_tr_c, self.X_ho_c, self.y_tr_c, self.y_ho_c\n",
    "        gc.collect()\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def transform(self):\n",
    "        return self.best_params \n",
    "\n",
    "class CsgoOutcomePredictor():\n",
    "\n",
    "    def __init__(self):\n",
    "        pass    \n",
    "    \n",
    "    def get_game_collection(self, PATH_TO_DIR):\n",
    "        \n",
    "        \"\"\"\n",
    "        Описание: коллекционирование респонсов парсера\n",
    "        Параметры: PATH_TO_DIR - путь до директории с респонсами\n",
    "        \"\"\"\n",
    "\n",
    "        L_FILENAMES = os.listdir(PATH_TO_DIR)\n",
    "        L_COLLECTION = []\n",
    "        for fnm in tqdm.tqdm(L_FILENAMES):\n",
    "            try:\n",
    "                pth = os.path.join(PATH_TO_DIR, fnm)\n",
    "                with open(pth, 'r') as f:\n",
    "                    d_rsp = json.load(f)\n",
    "                L_COLLECTION.append(d_rsp)\n",
    "            except:\n",
    "                pass\n",
    "        idx_ordered = np.argsort([d_game['id'] for d_game in L_COLLECTION])[::-1]\n",
    "        L_COLLECTION = np.array(L_COLLECTION)[idx_ordered].tolist()\n",
    "        return L_COLLECTION\n",
    "\n",
    "    def add_global_info(self, d_game):\n",
    "\n",
    "        d = {}\n",
    "\n",
    "        d['id'] = d_game['id']\n",
    "        d['match_id'] = d_game['match_id']\n",
    "        d['match_type'] = d_game['match']['match_type']\n",
    "        d['number_of_games'] = d_game['match']['number_of_games']\n",
    "        d['date'] = parser.parse(d_game['begin_at'])\n",
    "        d['map_id'] = d_game['map']['id']\n",
    "        d['league_id'] = d_game['match']['league']['id']\n",
    "        d['serie_id'] = d_game['match']['serie']['id']\n",
    "        d['tournament_id'] = d_game['match']['tournament']['id']\n",
    "        d['serie_tier'] = d_game['match']['serie']['tier']\n",
    "\n",
    "        return d\n",
    "\n",
    "    def add_profile(self, d_game):\n",
    "            \n",
    "        # идентификаторы актуальных карт\n",
    "        l_map2use = [1, 2, 6, 7, 8, 20, 31]\n",
    "        # ключи со статистикой игрока\n",
    "        l_stat_keys = ['adr', 'assists', 'deaths', 'first_kills_diff', 'flash_assists', \n",
    "                    'headshots', 'k_d_diff', 'kast', 'kills', 'rating']\n",
    "\n",
    "        # информация об игре\n",
    "        d_info = self.add_global_info(d_game)\n",
    "        \n",
    "        if d_info['map_id'] in l_map2use:  \n",
    "\n",
    "            d_r1 = d_game['rounds'][0]\n",
    "            if d_r1['round']==1:\n",
    "                \n",
    "                # информация о раундах\n",
    "                df_rounds = pd.DataFrame.from_records(d_game['rounds'])\n",
    "                start_ct_id =d_r1['ct']   \n",
    "                winner_id = df_rounds['winner_team'].value_counts().idxmax()\n",
    "                maxround = df_rounds['round'].max()\n",
    "                d_h1_win_count = df_rounds.query('round<=15')['winner_team'].value_counts().to_dict()\n",
    "                d_h2_win_count = df_rounds.query('round>15')['winner_team'].value_counts().to_dict()\n",
    "                d_h1_outcome_count = df_rounds.query('round<=15')['outcome'].value_counts().to_dict()\n",
    "                d_h2_outcome_count = df_rounds.query('round>15')['outcome'].value_counts().to_dict()        \n",
    "\n",
    "                L = []\n",
    "                counter = 0\n",
    "                # информация об игроках\n",
    "                for p in d_game['players']:\n",
    "                    counter+=1\n",
    "\n",
    "                    d = {}\n",
    "                    d.update(d_info)\n",
    "\n",
    "                    # идентификатор игрока\n",
    "                    d['player_id'] = p['player']['id']\n",
    "                    # идентификатор команды\n",
    "                    d['team_id'] = p['team']['id']\n",
    "                    # идентификатор оппонента\n",
    "                    d['opponent_id'] = p['opponent']['id']\n",
    "\n",
    "                    # национальность игрока\n",
    "                    d['player_nationality']  = p['player']['nationality']\n",
    "                    # дата рождения игрока\n",
    "                    d['player_birthday']  = p['player']['birthday']\n",
    "                    # страна команды\n",
    "                    d['team_location']  = p['team']['location']\n",
    "\n",
    "                    # сторона начала\n",
    "                    d['start_ct']= 1 if start_ct_id==d['team_id'] else 0\n",
    "                    # победа\n",
    "                    d['win'] = 1 if winner_id==d['team_id'] else 0\n",
    "                    # все раундов в игре\n",
    "                    d['maxround'] = maxround\n",
    "\n",
    "                    # число выигранных раундов в 1-ой половине игры\n",
    "                    try:\n",
    "                        d['h1_win_count'] = d_h1_win_count[d['team_id']]\n",
    "                    except:\n",
    "                        d['h1_win_count'] = 0 \n",
    "                    # число выигранных раундов во 2-ой половине игры\n",
    "                    try:\n",
    "                        d['h2_win_count'] = d_h2_win_count[d['team_id']]\n",
    "                    except:\n",
    "                        d['h2_win_count'] = 0 \n",
    "                    # исходы раундов в 1-ой половине игры\n",
    "                    for k, v in d_h1_outcome_count.items():\n",
    "                        d[f'h1_outcome_{k}_count'] = v\n",
    "                    # исходы раундов во 2-ой половине игры\n",
    "                    for k, v in d_h2_outcome_count.items():\n",
    "                        d[f'h2_outcome_{k}_count'] = v            \n",
    "\n",
    "                    # статистика игрока\n",
    "                    d.update({k:p[k] if pd.notnull(p[k]) else 0.0 for k in l_stat_keys})\n",
    "                    d.update({f'{k}_per_round':p[k]/maxround if pd.notnull(p[k]) else 0.0 for k in l_stat_keys})\n",
    "\n",
    "                    L.append(d)\n",
    "                if counter==10:\n",
    "                    return L\n",
    "                else:\n",
    "                    return None\n",
    "            else:\n",
    "                return None\n",
    "\n",
    "    def get_profiles(self, L_COLLECTION):\n",
    "\n",
    "        \"\"\"\n",
    "        Описание: профайлинг игроков в играх\n",
    "        Параметры: L_COLLECTION- коллекция респонсов\n",
    "        \"\"\"        \n",
    "            \n",
    "        # информация об игре\n",
    "        L_GLOBAL_KEYS = [\n",
    "            'id', 'match_id', 'match_type', 'number_of_games',\n",
    "            'date', 'year', 'month', 'day', 'weekday', 'hour',\n",
    "            'map_id',\n",
    "            'league_id', 'serie_id', 'tournament_id', 'serie_tier',\n",
    "            'start_ct'\n",
    "        ]\n",
    "        # ключи для агрегирования\n",
    "        L_AGG_KEYS = [    \n",
    "            \n",
    "            'h1_outcome_defused_count', 'h1_outcome_eliminated_count',\n",
    "            'h1_outcome_exploded_count', 'h1_outcome_timeout_count',\n",
    "            'h1_win_count', 'h2_outcome_defused_count',\n",
    "            'h2_outcome_eliminated_count', 'h2_outcome_exploded_count',\n",
    "            'h2_outcome_timeout_count', 'h2_win_count',\n",
    "\n",
    "            'win', 'maxround',\n",
    "\n",
    "            'adr', 'assists', 'deaths', 'first_kills_diff', 'flash_assists', 'headshots',\n",
    "            'k_d_diff', 'kast', 'kills', 'rating', \n",
    "            'adr_per_round', 'assists_per_round', 'deaths_per_round', 'first_kills_diff_per_round', 'flash_assists_per_round', 'headshots_per_round',\n",
    "            'k_d_diff_per_round', 'kast_per_round', 'kills_per_round','rating_per_round'\n",
    "        ]\n",
    "        # ключи для группировки\n",
    "        L_GROUP_KEYS = [\n",
    "            'team_id', 'opponent_id', 'team_location', 'lineup'\n",
    "        ]\n",
    "\n",
    "        # профайлинг игрока\n",
    "        L_player_profile = []\n",
    "        for d_game in tqdm.tqdm(L_COLLECTION):\n",
    "            try:\n",
    "                L_player_profile.extend(self.add_profile(d_game))        \n",
    "            except:\n",
    "                pass\n",
    "        df_player_profile = pd.DataFrame.from_records(L_player_profile)\n",
    "        del L_player_profile\n",
    "        gc.collect()\n",
    "\n",
    "        L_dict = []\n",
    "        for (game_id, team_id), subdf in tqdm.tqdm(df_player_profile.groupby(['id', 'team_id'])):\n",
    "            n_players = subdf.shape[0]\n",
    "            if n_players==5:\n",
    "                subdf_c = subdf.copy()\n",
    "                lineup = '-'.join(subdf['player_id'].sort_values().astype(str))\n",
    "                subdf_c['lineup'] = lineup\n",
    "                L_dict.extend(subdf_c.to_dict('records'))\n",
    "        del df_player_profile\n",
    "        gc.collect()\n",
    "        df_player_profile = pd.DataFrame.from_records(L_dict).sort_values('date')\n",
    "        del L_dict\n",
    "        gc.collect()\n",
    "\n",
    "        date = df_player_profile['date']\n",
    "        df_player_profile['year'] = date.dt.year\n",
    "        df_player_profile['month'] = date.dt.month\n",
    "        df_player_profile['day'] = date.dt.day\n",
    "        df_player_profile['weekday'] = date.dt.weekday\n",
    "        df_player_profile['hour'] = date.dt.hour\n",
    "        df_player_profile[['serie_tier', 'team_location']] = df_player_profile[['serie_tier', 'team_location']].fillna('default')    \n",
    "\n",
    "        # профайлинг команды\n",
    "        L_team_profile = []\n",
    "        for (game_id, team_id), subdf in tqdm.tqdm(df_player_profile.groupby(['id', 'team_id'])):    \n",
    "            d = subdf[L_GLOBAL_KEYS+L_GROUP_KEYS].iloc[0].to_dict()    \n",
    "            d.update(subdf[L_AGG_KEYS].mean().to_dict())\n",
    "            L_team_profile.append(d)\n",
    "        df_team_profile = pd.DataFrame.from_records(L_team_profile)\n",
    "        del L_team_profile\n",
    "        gc.collect()\n",
    "\n",
    "        return {'player':df_player_profile, 'team':df_team_profile}\n",
    "\n",
    "    def add_info4game(self, game_id):  \n",
    "\n",
    "        L_GAMEINFO_KEYS = [\n",
    "            'id',\n",
    "            'number_of_games',\n",
    "            'year','month', 'day', 'weekday', 'hour',\n",
    "            'map_id',\n",
    "            'league_id', 'serie_id', 'tournament_id', \n",
    "            'serie_tier'\n",
    "        ]\n",
    "        \n",
    "        df_game = self.df_team_profile.query('id==@game_id')\n",
    "\n",
    "        d_fs4gm = {}\n",
    "        d_fs4gm.update(df_game[L_GAMEINFO_KEYS].iloc[0].to_dict())\n",
    "\n",
    "        d_team_id2start_ct = dict(zip(df_game['team_id'], df_game['start_ct']))\n",
    "        d_team_id2opponent_id = dict(zip(df_game['team_id'], df_game['opponent_id']))\n",
    "        d_team_id2lineup = dict(zip(df_game['team_id'], df_game['lineup']))\n",
    "        d_team_id2loc = dict(zip(df_game['team_id'], df_game['team_location']))\n",
    "\n",
    "        df_game = self.df_player_profile.query('id==@game_id')\n",
    "\n",
    "        for team_id, subdf in df_game.groupby('team_id'):\n",
    "\n",
    "            prefix = 'start_ct' if d_team_id2start_ct[team_id]==1 else 'start_t'\n",
    "\n",
    "            d_fs4gm[f'{prefix}__team_id'] = team_id    \n",
    "            d_fs4gm[f'{prefix}__team_lineup'] = d_team_id2lineup[team_id]\n",
    "            d_fs4gm[f'{prefix}__team_location'] = d_team_id2loc[team_id]\n",
    "            \n",
    "            subdf = subdf.sort_values('player_id')    \n",
    "            L_p_id = subdf['player_id'].values    \n",
    "            d_player_id2nat = dict(zip(subdf['player_id'], subdf['player_nationality']))\n",
    "            ser_bd = subdf['player_birthday'].astype('datetime64')\n",
    "            ser_bd_y = ser_bd.dt.year\n",
    "            ser_bd_m = ser_bd.dt.month\n",
    "            ser_bd_d = ser_bd.dt.day\n",
    "\n",
    "            for i, p_id in enumerate(L_p_id):\n",
    "                d_fs4gm[f'{prefix}__player{i+1}_id'] = p_id\n",
    "                d_fs4gm[f'{prefix}__player{i+1}_nationality'] = d_player_id2nat[p_id]\n",
    "                d_fs4gm[f'{prefix}__player{i+1}_birthday_year'] = ser_bd_y.iloc[i]\n",
    "                d_fs4gm[f'{prefix}__player{i+1}_birthday_month'] = ser_bd_m.iloc[i]\n",
    "                d_fs4gm[f'{prefix}__player{i+1}_birthday_day'] = ser_bd_d.iloc[i]  \n",
    "        return d_fs4gm\n",
    "\n",
    "    def add_features__gameinfo(self, PATH_TO_GAMEINFO_FEATURES):        \n",
    "\n",
    "        ls = os.listdir(PATH_TO_GAMEINFO_FEATURES)\n",
    "        L_GAME_IDXS = np.unique(self.df_team_profile['id'])\n",
    "        try:\n",
    "            set_in = set([int(x.split('.')[0]) for x in ls])\n",
    "        except:\n",
    "            set_in = set()\n",
    "        set_all = set(L_GAME_IDXS)\n",
    "        set_new = set_all-set_in\n",
    "        L_GAME_IDXS = list(set_new)[::-1]\n",
    "\n",
    "        for game_id in tqdm.tqdm(L_GAME_IDXS):\n",
    "            try:    \n",
    "                d_fs4gm = self.add_info4game(game_id)\n",
    "                pth = os.path.join(PATH_TO_GAMEINFO_FEATURES, '{}.pickle'.format(game_id))\n",
    "                with open(pth, 'wb') as f:\n",
    "                    pickle.dump(d_fs4gm, f)\n",
    "                del d_fs4gm\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    def add_features__team4game(self, game_id):  \n",
    "\n",
    "        L_GROUP_KEYS = [        \n",
    "            'number_of_games',\n",
    "            'year','month', 'day', 'weekday', 'hour',\n",
    "            'serie_tier'\n",
    "        ]\n",
    "        L_FILTER_KEYS = [\n",
    "            'league_id', 'serie_id', 'tournament_id'\n",
    "        ]\n",
    "\n",
    "        # ключи для агрегирования\n",
    "        L_AGG_KEYS = [  \n",
    "\n",
    "            'maxround', 'win', \n",
    "            \n",
    "            'h1_outcome_defused_count', 'h1_outcome_eliminated_count',\n",
    "            'h1_outcome_exploded_count', 'h1_outcome_timeout_count',\n",
    "            'h1_win_count', 'h2_outcome_defused_count',\n",
    "            'h2_outcome_eliminated_count', 'h2_outcome_exploded_count',\n",
    "            'h2_outcome_timeout_count', 'h2_win_count',    \n",
    "\n",
    "            'adr', 'first_kills_diff', 'k_d_diff', 'kast','rating', \n",
    "            'assists_per_round', 'deaths_per_round',\n",
    "            'flash_assists_per_round', 'headshots_per_round',\n",
    "            'kills_per_round'\n",
    "            \n",
    "        ]\n",
    "\n",
    "        L_BY_KEYS = [\n",
    "            'number_of_games',\n",
    "            'year','month', 'day', 'weekday', 'hour',\n",
    "            'serie_tier'\n",
    "        ]\n",
    "        \n",
    "        df_game = self.df_team_profile.query('id==@game_id')\n",
    "\n",
    "        date = df_game['date'].iloc[0]\n",
    "        map_id = df_game['map_id'].iloc[0]\n",
    "        league_id = df_game['league_id'].iloc[0]\n",
    "        serie_id = df_game['serie_id'].iloc[0]\n",
    "        tournament_id = df_game['tournament_id'].iloc[0]\n",
    "        d_filter = dict(zip(['league_id', 'serie_id', 'tournament_id'], [league_id, serie_id, tournament_id]))\n",
    "\n",
    "        d_fs4gm = {'id':game_id}    \n",
    "\n",
    "        d_team_id2start_ct = dict(zip(df_game['team_id'], df_game['start_ct']))\n",
    "        d_team_id2opponent_id = dict(zip(df_game['team_id'], df_game['opponent_id']))\n",
    "        d_team_id2lineup = dict(zip(df_game['team_id'], df_game['lineup']))\n",
    "        d_team_id2loc = dict(zip(df_game['team_id'], df_game['team_location']))\n",
    "        \n",
    "\n",
    "        for team_id, start_ct in d_team_id2start_ct.items():\n",
    "\n",
    "            opponent_id = d_team_id2opponent_id[team_id]\n",
    "            lineup = d_team_id2lineup[team_id]\n",
    "\n",
    "            prefix = 'start_ct' if start_ct==1 else 'start_t'\n",
    "\n",
    "            df_history = self.df_team_profile.query('(date<@date)&(team_id==@team_id)')\n",
    "            df_history_on_map_with_start = df_history.query('(map_id==@map_id)&(start_ct==@start_ct)')        \n",
    "            df_history_with_lineup = df_history.query('lineup==@lineup')\n",
    "            df_history_on_map_with_start_and_lineup = df_history.query('(map_id==@map_id)&(start_ct==@start_ct)&(lineup==@lineup)')\n",
    "            df_history_pair = df_history.query('opponent_id==@opponent_id')\n",
    "            df_history_on_map_with_start_and_pair = df_history.query('(map_id==@map_id)&(start_ct==@start_ct)&(opponent_id==@opponent_id)')\n",
    "\n",
    "            L_DF = [\n",
    "                df_history, df_history_on_map_with_start, \n",
    "                df_history_with_lineup, df_history_on_map_with_start_and_lineup,\n",
    "                df_history_pair, df_history_on_map_with_start_and_pair\n",
    "            ]\n",
    "            L_SUFFIX = [\n",
    "                'all_map_all_start', 'current_map_current_start', \n",
    "                'all_map_all_start__lineup', 'current_map_current_start__lineup',\n",
    "                'all_map_all_start__pair', 'current_map_current_start__pair',\n",
    "            ]\n",
    "\n",
    "            for filter_key, filter_value in d_filter.items():\n",
    "                for suffix, df in zip(['all_map_all_start', 'current_map_current_start'],\n",
    "                                    [df_history, df_history_on_map_with_start, ]):\n",
    "                    L_SUFFIX.append(filter_key)\n",
    "                    L_DF.append(df[df[filter_key]==filter_value])\n",
    "\n",
    "            d_dicts4team = dict(zip(L_SUFFIX, L_DF))\n",
    "            del L_SUFFIX, L_DF\n",
    "\n",
    "            \n",
    "            for suffix, subdf in d_dicts4team.items():                       \n",
    "                for key in L_AGG_KEYS:\n",
    "                    values = subdf[key].values\n",
    "                    d_fs4gm[f'{prefix}__team__{suffix}__{key}__mean'] = np.mean(values)\n",
    "                    d_fs4gm[f'{prefix}__team__{suffix}__{key}__sum'] = np.sum(values)\n",
    "                    for by_key in L_BY_KEYS:\n",
    "                        for by_value, subsubdf in subdf.groupby(by_key):\n",
    "                            values = subsubdf[key].values\n",
    "                            try:\n",
    "                                d_fs4gm[f'{prefix}__team__{suffix}__{by_key}_{int(by_value)}__{key}__mean'] = np.mean(values)\n",
    "                                d_fs4gm[f'{prefix}__team__{suffix}__{by_key}_{int(by_value)}__{key}__sum'] = np.sum(values)\n",
    "                            except:\n",
    "                                d_fs4gm[f'{prefix}__team__{suffix}__{by_key}_{by_value}__{key}__mean'] = np.mean(values)\n",
    "                                d_fs4gm[f'{prefix}__team__{suffix}__{by_key}_{by_value}__{key}__sum'] = np.sum(values)\n",
    "            del d_dicts4team\n",
    "\n",
    "        return d_fs4gm   \n",
    "\n",
    "    def add_features__team(self, PATH_TO_FEATURES_TEAM): \n",
    "        ls = os.listdir(PATH_TO_FEATURES_TEAM)\n",
    "        L_GAME_IDXS = np.unique(self.df_team_profile['id'])\n",
    "        try:\n",
    "            set_in = set([int(x.split('.')[0]) for x in ls])\n",
    "        except:\n",
    "            set_in = set()\n",
    "        set_all = set(L_GAME_IDXS)\n",
    "        set_new = set_all-set_in\n",
    "        L_GAME_IDXS = list(set_new)[::-1]\n",
    "\n",
    "        for game_id in tqdm.tqdm(L_GAME_IDXS):\n",
    "            try:    \n",
    "                d_fs4gm = self.add_features__team4game(game_id)\n",
    "                pth = os.path.join(PATH_TO_FEATURES_TEAM, '{}.pickle'.format(game_id))\n",
    "                with open(pth, 'wb') as f:\n",
    "                    pickle.dump(d_fs4gm, f)\n",
    "                del d_fs4gm\n",
    "            except:\n",
    "                pass   \n",
    "\n",
    "    def add_features__player4game(self, game_id):  \n",
    "\n",
    "        L_GROUP_KEYS = [        \n",
    "            'number_of_games',\n",
    "            'year','month', 'day', 'weekday', 'hour',\n",
    "            'serie_tier'\n",
    "        ]\n",
    "        L_FILTER_KEYS = [\n",
    "            'league_id', 'serie_id', 'tournament_id'\n",
    "        ]\n",
    "\n",
    "        # ключи для агрегирования\n",
    "        L_AGG_KEYS = [  \n",
    "            \n",
    "            'adr', 'first_kills_diff', 'k_d_diff', 'kast', 'rating', \n",
    "            'assists_per_round', 'deaths_per_round',\n",
    "            'flash_assists_per_round', 'headshots_per_round',\n",
    "            'kills_per_round'\n",
    "            \n",
    "        ]\n",
    "\n",
    "        L_BY_KEYS = [            \n",
    "            'year','month', 'day', 'weekday', 'hour'\n",
    "            \n",
    "        ]\n",
    "        \n",
    "        df_game = self.df_player_profile.query('id==@game_id')\n",
    "\n",
    "        date = df_game['date'].iloc[0]\n",
    "        map_id = df_game['map_id'].iloc[0]\n",
    "        league_id = df_game['league_id'].iloc[0]\n",
    "        serie_id = df_game['serie_id'].iloc[0]\n",
    "        tournament_id = df_game['tournament_id'].iloc[0]\n",
    "        d_filter = dict(zip(['league_id', 'serie_id', 'tournament_id'], [league_id, serie_id, tournament_id]))\n",
    "\n",
    "        d_fs4gm = {'id':game_id}    \n",
    "\n",
    "        d_team_id2start_ct = dict(zip(df_game['team_id'], df_game['start_ct']))   \n",
    "\n",
    "        for team_id, start_ct in d_team_id2start_ct.items():        \n",
    "\n",
    "            prefix = 'start_ct' if start_ct==1 else 'start_t'\n",
    "\n",
    "            L_p_id = np.unique(df_game.query('team_id==@team_id')['player_id'])\n",
    "\n",
    "            for i, p_id in enumerate(L_p_id):\n",
    "\n",
    "                df_in_team_history = self.df_player_profile.query('(date<@date)&(player_id==@p_id)&(team_id==@team_id)')\n",
    "                df_in_team_history_on_map_with_start = df_in_team_history.query('(map_id==@map_id)&(start_ct==@start_ct)')  \n",
    "                df_not_in_team_history = self.df_player_profile.query('(date<@date)&(player_id==@p_id)&(team_id!=@team_id)')\n",
    "                df_not_in_team_history_on_map_with_start = df_in_team_history.query('(map_id==@map_id)&(start_ct==@start_ct)') \n",
    "\n",
    "                L_DF = [\n",
    "                    df_in_team_history, df_in_team_history_on_map_with_start, \n",
    "                    df_not_in_team_history, df_not_in_team_history_on_map_with_start                \n",
    "                ]\n",
    "                L_SUFFIX = [\n",
    "                    f'player{i+1}__in_team__all_map_all_start', f'player{i+1}__in_team__current_map_current_start', \n",
    "                    f'player{i+1}__not_in_team__all_map_all_start', f'player{i+1}__not_in_team__current_map_current_start', \n",
    "                ]        \n",
    "\n",
    "                d_dicts4player = dict(zip(L_SUFFIX, L_DF))\n",
    "                del L_SUFFIX, L_DF\n",
    "\n",
    "            \n",
    "                for suffix, subdf in d_dicts4player.items():                       \n",
    "                    for key in L_AGG_KEYS:\n",
    "                        values = subdf[key].values\n",
    "                        d_fs4gm[f'{prefix}__{suffix}__{key}__mean'] = np.mean(values)\n",
    "                        d_fs4gm[f'{prefix}__{suffix}__{key}__sum'] = np.sum(values)\n",
    "                        for by_key in L_BY_KEYS:\n",
    "                            for by_value, subsubdf in subdf.groupby(by_key):\n",
    "                                values = subsubdf[key].values\n",
    "                                try:\n",
    "                                    d_fs4gm[f'{prefix}__{suffix}__{by_key}_{int(by_value)}__{key}__mean'] = np.mean(values)\n",
    "                                    d_fs4gm[f'{prefix}__{suffix}__{by_key}_{int(by_value)}__{key}__sum'] = np.sum(values)\n",
    "                                except:\n",
    "                                    d_fs4gm[f'{prefix}__{suffix}__{by_key}_{by_value}__{key}__mean'] = np.mean(values)\n",
    "                                    d_fs4gm[f'{prefix}__{suffix}__{by_key}_{by_value}__{key}__sum'] = np.sum(values)\n",
    "                del d_dicts4player\n",
    "\n",
    "        return d_fs4gm\n",
    "\n",
    "    def add_features__player(self, PATH_TO_FEATURES_PLAYER): \n",
    "        ls = os.listdir(PATH_TO_FEATURES_PLAYER)\n",
    "        L_GAME_IDXS = np.unique(self.df_player_profile['id'])\n",
    "        try:\n",
    "            set_in = set([int(x.split('.')[0]) for x in ls])\n",
    "        except:\n",
    "            set_in = set()\n",
    "        set_all = set(L_GAME_IDXS)\n",
    "        set_new = set_all-set_in\n",
    "        L_GAME_IDXS = list(set_new)[::-1]\n",
    "\n",
    "        for game_id in tqdm.tqdm(L_GAME_IDXS):\n",
    "            try:    \n",
    "                d_fs4gm = self.add_features__player4game(game_id)\n",
    "                pth = os.path.join(PATH_TO_FEATURES_PLAYER, '{}.pickle'.format(game_id))\n",
    "                with open(pth, 'wb') as f:\n",
    "                    pickle.dump(d_fs4gm, f)\n",
    "                del d_fs4gm\n",
    "            except:\n",
    "                pass  \n",
    "\n",
    "    def reduce_mem_usage(self, series):\n",
    "        try:\n",
    "            col_type = series.dtype\n",
    "\n",
    "            if col_type != object:\n",
    "                c_min = series.min()\n",
    "                c_max = series.max()\n",
    "                if str(col_type)[:3] == 'int':\n",
    "                    if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                        series = series.astype(np.int8)\n",
    "                    elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                        series = series.astype(np.int16)\n",
    "                    elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                        series = series.astype(np.int32)\n",
    "                    elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                        series = series.astype(np.int64)  \n",
    "                else:\n",
    "                    if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                        series = series.astype(np.float16)\n",
    "                    elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                        series = series.astype(np.float32)\n",
    "                    else:\n",
    "                        series = series.astype(np.float64)\n",
    "            else:\n",
    "                pass \n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        return series \n",
    "\n",
    "    def build_features(self, PATH_TO_FEATURES_GAMEINFO, PATH_TO_FEATURES_TEAM, PATH_TO_FEATURES_PLAYER):\n",
    "\n",
    "        \"\"\"\n",
    "        Сборка признаков\n",
    "        \"\"\"   \n",
    "\n",
    "        # все файлы с признаками\n",
    "        set_gameinfo= set(os.listdir(PATH_TO_FEATURES_GAMEINFO))\n",
    "        set_team= set(os.listdir(PATH_TO_FEATURES_TEAM))\n",
    "        set_player= set(os.listdir(PATH_TO_FEATURES_PLAYER))\n",
    "        l_all_files = np.array(list(set.intersection(*[set_gameinfo, set_team, set_player])))\n",
    "        l_all_files = l_all_files[np.argsort([int(x.split('.')[0]) for x in l_all_files])]\n",
    "\n",
    "        # размер батча\n",
    "        batch_size = 100\n",
    "        n = np.int32(np.ceil(len(l_all_files) / batch_size))\n",
    "        l_batches = np.array_split(l_all_files, n)\n",
    "\n",
    "        # сборка\n",
    "        df_features = pd.DataFrame()\n",
    "        for batch in tqdm.tqdm(l_batches):\n",
    "            \n",
    "            l = []\n",
    "            for fnm in batch:\n",
    "                D = {}\n",
    "                for pth2dir in [PATH_TO_FEATURES_GAMEINFO, PATH_TO_FEATURES_TEAM, PATH_TO_FEATURES_PLAYER]:\n",
    "                    pth = os.path.join(pth2dir, fnm)\n",
    "                    with open(pth, 'rb') as f:\n",
    "                        d = pickle.load(f)\n",
    "                    D.update(d)\n",
    "                    del d\n",
    "                l.append(D)\n",
    "                del D\n",
    "            \n",
    "            df = pd.DataFrame.from_records(l).apply(self.reduce_mem_usage)\n",
    "            del l\n",
    "            df_features = df_features.append(df)\n",
    "            del df\n",
    "        \n",
    "        return df_features\n",
    "\n",
    "    def build_targets(self, L_GAME_IDXS):\n",
    "    \n",
    "        \"\"\"\n",
    "        Сборка челевых переменных (победа, тотал м/б, число выигранных раундов в 1/2 половинах за обе стороны)\n",
    "        \"\"\"    \n",
    "        df_targets = pd.DataFrame()\n",
    "        for d_rsp in tqdm.tqdm(self.L_COLLECTION):  \n",
    "\n",
    "            try:\n",
    "                \n",
    "                game_id = d_rsp['id']\n",
    "                if game_id in L_GAME_IDXS:\n",
    "                    ###########################################################################    \n",
    "                    df_rounds = pd.DataFrame.from_records(d_rsp['rounds'])\n",
    "\n",
    "                    maxround = df_rounds['round'].max()\n",
    "                    start_ct_id = df_rounds.query('round==1')['ct'].iloc[0]\n",
    "                    start_t_id = df_rounds.query('round==1')['terrorists'].iloc[0]\n",
    "                    df_h1 = df_rounds.query('round<=15')\n",
    "                    df_h2 = df_rounds.query('round>15')\n",
    "                    d_h1_win_count = df_h1['winner_team'].value_counts().to_dict()\n",
    "                    d_h2_win_count = df_h2['winner_team'].value_counts().to_dict()\n",
    "                    d_h1h2_win_count = df_rounds['winner_team'].value_counts().to_dict()\n",
    "                    winner_id = df_rounds['winner_team'].value_counts().idxmax()\n",
    "                    \n",
    "\n",
    "                    #############################################################################\n",
    "\n",
    "                    d_targets4game = {'id':game_id}\n",
    "                    \n",
    "                    d_targets4game['start_ct__win'] = int(winner_id==start_ct_id)\n",
    "\n",
    "                    for i in range(16, 31):\n",
    "\n",
    "                        d_targets4game[f'total__b__{i}'] = int(maxround>=i)\n",
    "                        d_targets4game[f'total__m__{i}'] = int(maxround<=i)\n",
    "\n",
    "                    for i in range(1, 16):\n",
    "\n",
    "                        d_targets4game[f'h1__start_ct_win__b__{i}'] = int(d_h1_win_count[start_ct_id]>=i)\n",
    "                        d_targets4game[f'h1__start_ct_win__m__{i}'] = int(d_h1_win_count[start_ct_id]<=i)    \n",
    "                        d_targets4game[f'h1__start_t_win__b__{i}'] = int(d_h1_win_count[start_t_id]>=i)\n",
    "                        d_targets4game[f'h1__start_t_win__m__{i}'] = int(d_h1_win_count[start_t_id]<=i)\n",
    "\n",
    "                        d_targets4game[f'h2__start_ct_win__b__{i}'] = int(d_h2_win_count[start_ct_id]>=i)\n",
    "                        d_targets4game[f'h2__start_ct_win__m__{i}'] = int(d_h2_win_count[start_ct_id]<=i)    \n",
    "                        d_targets4game[f'h2__start_t_win__b__{i}'] = int(d_h1_win_count[start_t_id]>=i)\n",
    "                        d_targets4game[f'h2__start_t_win__m__{i}'] = int(d_h1_win_count[start_t_id]<=i)\n",
    "\n",
    "                        d_targets4game[f'h1h2__start_ct_win__b__{i}'] = int(d_h1h2_win_count[start_ct_id]>=i)\n",
    "                        d_targets4game[f'h1h2__start_ct_win__m__{i}'] = int(d_h1h2_win_count[start_ct_id]<=i)\n",
    "                        d_targets4game[f'h1h2__start_t_win__b__{i}'] = int(d_h1h2_win_count[start_t_id]>=i)\n",
    "                        d_targets4game[f'h1h2__start_t_win__m__{i}'] = int(d_h1h2_win_count[start_t_id]<=i)                     \n",
    "\n",
    "                    df_targets = df_targets.append(d_targets4game, ignore_index = True)\n",
    "\n",
    "            except:\n",
    "                pass \n",
    "        df_targets['id'] = df_targets['id'].astype(int)\n",
    "        \n",
    "        return df_targets\n",
    "\n",
    "    def prepare_data(self, df_targets, df_features):\n",
    "\n",
    "        df_targets = df_targets.set_index('id').astype(int)\n",
    "        df_features = df_features.set_index('id')\n",
    "        games2use= np.intersect1d(df_features.index, df_targets.index)\n",
    "\n",
    "        X = df_features.loc[games2use]\n",
    "        del df_features\n",
    "        gc.collect()\n",
    "        L_CAT_FEATURES = [\n",
    "            'number_of_games', 'year', 'month', 'day', 'weekday', 'hour',\n",
    "            'map_id', 'league_id', 'serie_id', 'tournament_id', 'serie_tier',\n",
    "            'start_t__team_id', 'start_t__team_lineup', 'start_t__team_location',\n",
    "            'start_t__player1_id', 'start_t__player1_nationality',\n",
    "            'start_t__player1_birthday_year', 'start_t__player1_birthday_month',\n",
    "            'start_t__player1_birthday_day', 'start_t__player2_id',\n",
    "            'start_t__player2_nationality', 'start_t__player2_birthday_year',\n",
    "            'start_t__player2_birthday_month', 'start_t__player2_birthday_day',\n",
    "            'start_t__player3_id', 'start_t__player3_nationality',\n",
    "            'start_t__player3_birthday_year', 'start_t__player3_birthday_month',\n",
    "            'start_t__player3_birthday_day', 'start_t__player4_id',\n",
    "            'start_t__player4_nationality', 'start_t__player4_birthday_year',\n",
    "            'start_t__player4_birthday_month', 'start_t__player4_birthday_day',\n",
    "            'start_t__player5_id', 'start_t__player5_nationality',\n",
    "            'start_t__player5_birthday_year', 'start_t__player5_birthday_month',\n",
    "            'start_t__player5_birthday_day', 'start_ct__team_id',\n",
    "            'start_ct__team_lineup', 'start_ct__team_location',\n",
    "            'start_ct__player1_id', 'start_ct__player1_nationality',\n",
    "            'start_ct__player1_birthday_year', 'start_ct__player1_birthday_month',\n",
    "            'start_ct__player1_birthday_day', 'start_ct__player2_id',\n",
    "            'start_ct__player2_nationality', 'start_ct__player2_birthday_year',\n",
    "            'start_ct__player2_birthday_month', 'start_ct__player2_birthday_day',\n",
    "            'start_ct__player3_id', 'start_ct__player3_nationality',\n",
    "            'start_ct__player3_birthday_year', 'start_ct__player3_birthday_month',\n",
    "            'start_ct__player3_birthday_day', 'start_ct__player4_id',\n",
    "            'start_ct__player4_nationality', 'start_ct__player4_birthday_year',\n",
    "            'start_ct__player4_birthday_month', 'start_ct__player4_birthday_day',\n",
    "            'start_ct__player5_id', 'start_ct__player5_nationality',\n",
    "            'start_ct__player5_birthday_year', 'start_ct__player5_birthday_month',\n",
    "            'start_ct__player5_birthday_day'\n",
    "        ]\n",
    "\n",
    "        for key in L_CAT_FEATURES:\n",
    "            try:\n",
    "                X[key] = X[key].fillna(-9999).astype(int).astype('category')\n",
    "            except:\n",
    "                X[key] = X[key].fillna('default').astype('category')\n",
    "\n",
    "        L_NUM_FEATURES = X.drop(L_CAT_FEATURES, 1).columns\n",
    "        X[L_NUM_FEATURES] = X[L_NUM_FEATURES].fillna(-9999)\n",
    "        \n",
    "        Y = df_targets.loc[games2use]\n",
    "        del df_targets\n",
    "        gc.collect()    \n",
    "\n",
    "        X_obj = X.select_dtypes('category').astype('object')\n",
    "        L_obj_keys = X_obj.columns\n",
    "        for cmb in itertools.combinations(L_obj_keys, 2):\n",
    "            cmb= list(cmb)\n",
    "            new_key = '-'.join([str(x) for x in cmb])    \n",
    "            X[new_key] = X_obj[cmb].astype('str').apply(lambda x: '-'.join(x), axis = 1).astype('category')\n",
    "        del X_obj\n",
    "        gc.collect()\n",
    "\n",
    "        return X, Y\n",
    "\n",
    "    def run_ml_pipeline(self, X, y):\n",
    "\n",
    "        # итерации бустинга\n",
    "        CONST_PARAMS= {\n",
    "            'iterations':1000,\n",
    "            'loss_function':'Logloss',    \n",
    "            'verbose':1,\n",
    "        }\n",
    "        # сид рандома\n",
    "        SEED = 13\n",
    "        # доля тестовой части\n",
    "        TEST_SIZE= .05\n",
    "        # доля отложенной части\n",
    "        HOLD_SIZE = .2\n",
    "        # размер батча \n",
    "        BATCH_RATE = .2\n",
    "\n",
    "        # сплит\n",
    "        X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size = TEST_SIZE, shuffle = False)\n",
    "        X_tr, X_ho, y_tr, y_ho = train_test_split(X_tr, y_tr, test_size = HOLD_SIZE, shuffle = False)\n",
    "\n",
    "        # бъем признаки на батчи, чтобы не перегрузить оперативку\n",
    "        L_all_keys = X_tr.columns\n",
    "        L_batches = np.array_split(L_all_keys, np.int32(np.ceil(len(L_all_keys)/5000)))\n",
    "        \n",
    "        # отбираем признаки с ненулевой важностью\n",
    "        L_feat2use = []\n",
    "        for i, batch in enumerate(L_batches):\n",
    "            print('> batch#{}/{}'.format(i+1, len(L_batches)))\n",
    "            x_tr_batch = X_tr[batch]\n",
    "            x_ho_batch = X_ho[batch]\n",
    "            params = CONST_PARAMS.copy()\n",
    "            params['cat_features'] = np.where(x_tr_batch.dtypes=='category')[0]\n",
    "            model = cb.CatBoostClassifier(**params)        \n",
    "            model.fit(x_tr_batch, y_tr, eval_set=(x_ho_batch, y_ho), early_stopping_rounds=50)\n",
    "            mask = model.feature_importances_>0\n",
    "            L_feat2use.extend(batch[mask].tolist())\n",
    "            del x_tr_batch, x_ho_batch\n",
    "        X_tr_c, X_ho_c, X_te_c = X_tr[L_feat2use], X_ho[L_feat2use], X_te[L_feat2use]\n",
    "        del X_tr, X_ho, X_te\n",
    "        X_tr, X_ho, X_te = X_tr_c, X_ho_c, X_te_c\n",
    "        del X_tr_c, X_ho_c, X_te_c\n",
    "        gc.collect()\n",
    "\n",
    "        # рекурсивный отбор с ранней остановкой\n",
    "        i = 1\n",
    "        while True:\n",
    "            print('> iter#{}'.format(i))\n",
    "            params = CONST_PARAMS.copy()\n",
    "            params['cat_features'] = np.where(X_tr.dtypes=='category')[0]\n",
    "            model = cb.CatBoostClassifier(**params)        \n",
    "            model.fit(X_tr, y_tr, eval_set=(X_ho, y_ho), early_stopping_rounds=50)\n",
    "            mask = model.feature_importances_>0\n",
    "            if np.all(mask):\n",
    "                break\n",
    "            else:\n",
    "                X_tr, X_ho = X_tr.loc[:, mask], X_ho.loc[:, mask]\n",
    "                i+=1\n",
    "        X_te = X_te[X_tr.columns]\n",
    "        # оптимизация гиперпараметров\n",
    "        params = CONST_PARAMS.copy()\n",
    "        params['cat_features'] = np.where(X_tr.dtypes=='category')[0]\n",
    "        params['iterations'] = model.best_iteration_\n",
    "        params['verbose'] =0\n",
    "        model = cb.CatBoostClassifier(**params)    \n",
    "\n",
    "        cb_opt = CatBoostOptimizer(\n",
    "                        scoring_func= lambda y, y_proba: roc_auc_score(y, y_proba),\n",
    "                        const_params=params,\n",
    "                        seed=SEED, \n",
    "                        direction='maximize',\n",
    "                        n_trials=15\n",
    "            )\n",
    "\n",
    "        cb_opt.fit(X_tr, y_tr)\n",
    "        best_params = cb_opt.transform()\n",
    "        best_params['verbose'] = 0\n",
    "        best_params['random_state'] = SEED\n",
    "        \n",
    "\n",
    "        i = 1\n",
    "        while True:\n",
    "\n",
    "            print('> permutation importance iter#{}. n_features = {}'.format(i, X_tr.shape[1]))\n",
    "\n",
    "            params = best_params.copy()        \n",
    "            params['cat_features'] = np.where(X_tr.dtypes=='category')[0]\n",
    "            model = cb.CatBoostClassifier(**params)\n",
    "            model.fit(X_tr, y_tr)\n",
    "            params['iterations'] = model.best_iteration_\n",
    "            te_score_before=roc_auc_score(y_te, model.predict_proba(X_te)[:, 1])\n",
    "\n",
    "            L_perm_imp = []\n",
    "            for j in tqdm.tqdm(range(100)):\n",
    "                d_perm_imp = permutation_importance(model, X_ho, y_ho, scoring='roc_auc', n_repeats=1, random_state = SEED+j, n_jobs=-1)\n",
    "                L_perm_imp.append(d_perm_imp['importances_mean'].flatten())\n",
    "            arr_perm_imp_mean = np.mean(np.r_[L_perm_imp], 0)\n",
    "            idx_selected = np.where(arr_perm_imp_mean>0)[0]\n",
    "\n",
    "            params_c=params.copy()\n",
    "            params_c['cat_features'] = np.where(X_tr.iloc[:, idx_selected].dtypes=='category')[0]\n",
    "            model = cb.CatBoostClassifier(**params_c)\n",
    "            model.fit(X_tr.iloc[:, idx_selected], y_tr)\n",
    "            params_c['iterations'] = model.best_iteration_\n",
    "            te_score_after = roc_auc_score(y_te, model.predict_proba(X_te.iloc[:, idx_selected])[:, 1])\n",
    "\n",
    "            print('\\t> score before: {:.2f}, score after: {:.2f}'.format(te_score_before, te_score_after))\n",
    "            if te_score_after > te_score_before:\n",
    "                best_score = te_score_after\n",
    "                X_tr, X_ho, X_te = X_tr.iloc[:, idx_selected], X_ho.iloc[:, idx_selected], X_te.iloc[:, idx_selected]\n",
    "                i+=1\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        # оптимизация гиперпараметров\n",
    "        params = CONST_PARAMS.copy()\n",
    "        params['cat_features'] = np.where(X_tr.dtypes=='category')[0]\n",
    "        params['iterations'] = model.best_iteration_\n",
    "        params['verbose'] =0\n",
    "        model = cb.CatBoostClassifier(**params)    \n",
    "\n",
    "        cb_opt = CatBoostOptimizer(\n",
    "                        scoring_func= lambda y, y_proba: roc_auc_score(y, y_proba),\n",
    "                        const_params=params,\n",
    "                        seed=SEED, \n",
    "                        direction='maximize',\n",
    "                        n_trials=30\n",
    "            )\n",
    "        cb_opt.fit(X_tr, y_tr)\n",
    "        best_params = cb_opt.transform()\n",
    "        best_params['verbose'] = 0   \n",
    "        best_params['cat_features'] = np.where(X_tr.iloc[:, idx_selected].dtypes=='category')[0]\n",
    "        best_params['random_state'] = SEED \n",
    "        \n",
    "        features = X_tr.columns\n",
    "        d_res = {'params':best_params, 'roc_auc':best_score, 'features':features}\n",
    "\n",
    "        X_tr, X_ho, X_te, y_tr, y_ho, y_te\n",
    "        gc.collect()\n",
    "\n",
    "        return d_res\n",
    "\n",
    "    def fit(self, PATH_TO_RESPONSES, PATH_TO_FEATURES_GAMEINFO, PATH_TO_FEATURES_TEAM, PATH_TO_FEATURES_PLAYER):\n",
    "\n",
    "        time.sleep(1)\n",
    "        print('> collecting responses ...')\n",
    "        # коллекция респонсов\n",
    "        self.L_COLLECTION = self.get_game_collection(PATH_TO_RESPONSES)\n",
    "        print('----------------------------------------------------------------------------------\\n')\n",
    "\n",
    "\n",
    "        time.sleep(1)\n",
    "        print('> preparing team/player profiles ...')\n",
    "        # профайлинг игроков и команд в играх\n",
    "        d_profile = self.get_profiles(self.L_COLLECTION)\n",
    "        self.df_player_profile, self.df_team_profile = d_profile['player'], d_profile['team']\n",
    "        del d_profile\n",
    "        gc.collect()\n",
    "        print('----------------------------------------------------------------------------------\\n')\n",
    "\n",
    "\n",
    "        time.sleep(1)\n",
    "        print('> collecting features: 1. game info ...')\n",
    "        self.add_features__gameinfo(PATH_TO_FEATURES_GAMEINFO)\n",
    "\n",
    "        time.sleep(1)\n",
    "        print('> collecting features: 2. team history aggregation ...')\n",
    "        self.add_features__team(PATH_TO_FEATURES_TEAM)\n",
    "\n",
    "        time.sleep(1)\n",
    "        print('> collecting features: 3. player history aggregation ...')\n",
    "        self.add_features__player(PATH_TO_FEATURES_PLAYER)\n",
    "        print('----------------------------------------------------------------------------------\\n')\n",
    "\n",
    "\n",
    "        time.sleep(1)\n",
    "        print('> building features ...')\n",
    "        # df_features = self.build_features(PATH_TO_FEATURES_GAMEINFO, PATH_TO_FEATURES_TEAM, PATH_TO_FEATURES_PLAYER)\n",
    "        df_features = pd.read_pickle('df_features.pickle')\n",
    "\n",
    "        time.sleep(1)\n",
    "        print('> building targets ...')\n",
    "        L_GAME_IDXS = np.unique(df_features['id'])\n",
    "        # df_targets = self.build_targets(L_GAME_IDXS) \n",
    "        df_targets = pd.read_pickle('df_targets.pickle')\n",
    "        print('----------------------------------------------------------------------------------\\n')\n",
    "\n",
    "        time.sleep(1)\n",
    "        print('> preparing dataset for ml ...')\n",
    "        X, Y = self.prepare_data(df_targets, df_features)\n",
    "        del df_targets, df_features\n",
    "        gc.collect()\n",
    "        print('----------------------------------------------------------------------------------\\n')\n",
    "\n",
    "        time.sleep(1)\n",
    "        print('> running pipelines ...')\n",
    "        L_ALL_TARGET_KEYS = Y.columns\n",
    "        self.D_RESULTS = {}        \n",
    "        # выполянем пайплайн для целевых переменных\n",
    "        for i, target_key in enumerate(L_ALL_TARGET_KEYS):\n",
    "            print('\\t> iter#{}/{}. target: {} ...'.format(i+1, len(L_ALL_TARGET_KEYS), target_key))\n",
    "            y = Y[target_key].astype(int)\n",
    "            d_result = self.run_ml_pipeline(X, y)\n",
    "            self.D_RESULTS[target_key] = d_result\n",
    "            del d_result, y\n",
    "            print('----------------------------------------------------------------------------------\\n')\n",
    "\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 165/57761 [00:00<00:35, 1638.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> collecting responses ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 57761/57761 [00:33<00:00, 1708.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 78/57760 [00:00<01:17, 745.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> preparing team/player profiles ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 57760/57760 [04:38<00:00, 207.68it/s]\n",
      "100%|██████████| 69846/69846 [03:39<00:00, 317.82it/s]\n",
      "100%|██████████| 69846/69846 [01:48<00:00, 644.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> collecting features: 1. game info ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> collecting features: 2. team history aggregation ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> collecting features: 3. player history aggregation ...\n",
      "----------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> building features ...\n",
      "> building targets ...\n",
      "----------------------------------------------------------------------------------\n",
      "\n",
      "> preparing dataset for ml ...\n",
      "----------------------------------------------------------------------------------\n",
      "\n",
      "> running pipeline ...\n",
      "\t> iter#1/211. target: start_ct__win ...\n",
      "> batch#1/35\n",
      "Learning rate set to 0.029149\n",
      "0:\tlearn: 0.6905720\ttest: 0.6918694\tbest: 0.6918694 (0)\ttotal: 349ms\tremaining: 5m 49s\n",
      "1:\tlearn: 0.6855515\ttest: 0.6920366\tbest: 0.6918694 (0)\ttotal: 568ms\tremaining: 4m 43s\n",
      "2:\tlearn: 0.6832337\ttest: 0.6920430\tbest: 0.6918694 (0)\ttotal: 818ms\tremaining: 4m 31s\n",
      "3:\tlearn: 0.6798154\ttest: 0.6920855\tbest: 0.6918694 (0)\ttotal: 1.06s\tremaining: 4m 23s\n",
      "4:\tlearn: 0.6757836\ttest: 0.6923134\tbest: 0.6918694 (0)\ttotal: 1.31s\tremaining: 4m 20s\n",
      "5:\tlearn: 0.6721005\ttest: 0.6921238\tbest: 0.6918694 (0)\ttotal: 1.53s\tremaining: 4m 13s\n",
      "6:\tlearn: 0.6699597\ttest: 0.6925614\tbest: 0.6918694 (0)\ttotal: 1.77s\tremaining: 4m 10s\n",
      "7:\tlearn: 0.6673831\ttest: 0.6914858\tbest: 0.6914858 (7)\ttotal: 2s\tremaining: 4m 8s\n",
      "8:\tlearn: 0.6649678\ttest: 0.6913171\tbest: 0.6913171 (8)\ttotal: 2.23s\tremaining: 4m 5s\n",
      "9:\tlearn: 0.6624136\ttest: 0.6907600\tbest: 0.6907600 (9)\ttotal: 2.45s\tremaining: 4m 2s\n",
      "10:\tlearn: 0.6604485\ttest: 0.6907849\tbest: 0.6907600 (9)\ttotal: 2.69s\tremaining: 4m 1s\n",
      "11:\tlearn: 0.6562220\ttest: 0.6898956\tbest: 0.6898956 (11)\ttotal: 2.96s\tremaining: 4m 3s\n",
      "12:\tlearn: 0.6538631\ttest: 0.6901955\tbest: 0.6898956 (11)\ttotal: 3.4s\tremaining: 4m 18s\n",
      "13:\tlearn: 0.6517688\ttest: 0.6896623\tbest: 0.6896623 (13)\ttotal: 3.63s\tremaining: 4m 15s\n",
      "14:\tlearn: 0.6473974\ttest: 0.6885599\tbest: 0.6885599 (14)\ttotal: 3.87s\tremaining: 4m 13s\n",
      "15:\tlearn: 0.6444110\ttest: 0.6874829\tbest: 0.6874829 (15)\ttotal: 4.11s\tremaining: 4m 12s\n",
      "16:\tlearn: 0.6389427\ttest: 0.6886160\tbest: 0.6874829 (15)\ttotal: 4.34s\tremaining: 4m 11s\n",
      "17:\tlearn: 0.6374674\ttest: 0.6888641\tbest: 0.6874829 (15)\ttotal: 4.58s\tremaining: 4m 9s\n",
      "18:\tlearn: 0.6358867\ttest: 0.6891467\tbest: 0.6874829 (15)\ttotal: 4.81s\tremaining: 4m 8s\n",
      "19:\tlearn: 0.6334074\ttest: 0.6894091\tbest: 0.6874829 (15)\ttotal: 5.03s\tremaining: 4m 6s\n",
      "20:\tlearn: 0.6299101\ttest: 0.6885669\tbest: 0.6874829 (15)\ttotal: 5.28s\tremaining: 4m 6s\n",
      "21:\tlearn: 0.6277519\ttest: 0.6888891\tbest: 0.6874829 (15)\ttotal: 5.5s\tremaining: 4m 4s\n",
      "22:\tlearn: 0.6256257\ttest: 0.6875040\tbest: 0.6874829 (15)\ttotal: 5.71s\tremaining: 4m 2s\n",
      "23:\tlearn: 0.6233846\ttest: 0.6869931\tbest: 0.6869931 (23)\ttotal: 5.95s\tremaining: 4m 1s\n",
      "24:\tlearn: 0.6209828\ttest: 0.6879438\tbest: 0.6869931 (23)\ttotal: 6.39s\tremaining: 4m 9s\n",
      "25:\tlearn: 0.6192313\ttest: 0.6871963\tbest: 0.6869931 (23)\ttotal: 6.61s\tremaining: 4m 7s\n",
      "26:\tlearn: 0.6179379\ttest: 0.6876293\tbest: 0.6869931 (23)\ttotal: 6.82s\tremaining: 4m 5s\n",
      "27:\tlearn: 0.6159687\ttest: 0.6882038\tbest: 0.6869931 (23)\ttotal: 7.04s\tremaining: 4m 4s\n",
      "28:\tlearn: 0.6129354\ttest: 0.6874393\tbest: 0.6869931 (23)\ttotal: 7.29s\tremaining: 4m 4s\n",
      "29:\tlearn: 0.6103580\ttest: 0.6885249\tbest: 0.6869931 (23)\ttotal: 7.53s\tremaining: 4m 3s\n",
      "30:\tlearn: 0.6089207\ttest: 0.6883450\tbest: 0.6869931 (23)\ttotal: 7.76s\tremaining: 4m 2s\n",
      "31:\tlearn: 0.6074520\ttest: 0.6890416\tbest: 0.6869931 (23)\ttotal: 8s\tremaining: 4m 1s\n",
      "32:\tlearn: 0.6061029\ttest: 0.6892250\tbest: 0.6869931 (23)\ttotal: 8.22s\tremaining: 4m 1s\n",
      "33:\tlearn: 0.6040706\ttest: 0.6890193\tbest: 0.6869931 (23)\ttotal: 8.46s\tremaining: 4m\n",
      "34:\tlearn: 0.6001108\ttest: 0.6893794\tbest: 0.6869931 (23)\ttotal: 8.7s\tremaining: 3m 59s\n",
      "35:\tlearn: 0.5987499\ttest: 0.6898802\tbest: 0.6869931 (23)\ttotal: 8.94s\tremaining: 3m 59s\n",
      "36:\tlearn: 0.5965462\ttest: 0.6900244\tbest: 0.6869931 (23)\ttotal: 9.42s\tremaining: 4m 5s\n",
      "37:\tlearn: 0.5949357\ttest: 0.6904295\tbest: 0.6869931 (23)\ttotal: 9.65s\tremaining: 4m 4s\n",
      "38:\tlearn: 0.5936182\ttest: 0.6914933\tbest: 0.6869931 (23)\ttotal: 9.91s\tremaining: 4m 4s\n",
      "39:\tlearn: 0.5923197\ttest: 0.6915443\tbest: 0.6869931 (23)\ttotal: 10.2s\tremaining: 4m 3s\n",
      "40:\tlearn: 0.5911924\ttest: 0.6928437\tbest: 0.6869931 (23)\ttotal: 10.4s\tremaining: 4m 4s\n",
      "41:\tlearn: 0.5899314\ttest: 0.6929700\tbest: 0.6869931 (23)\ttotal: 10.7s\tremaining: 4m 3s\n",
      "42:\tlearn: 0.5867554\ttest: 0.6922936\tbest: 0.6869931 (23)\ttotal: 10.9s\tremaining: 4m 3s\n",
      "43:\tlearn: 0.5841892\ttest: 0.6928773\tbest: 0.6869931 (23)\ttotal: 11.2s\tremaining: 4m 3s\n",
      "44:\tlearn: 0.5831267\ttest: 0.6930526\tbest: 0.6869931 (23)\ttotal: 11.5s\tremaining: 4m 3s\n",
      "45:\tlearn: 0.5816062\ttest: 0.6934085\tbest: 0.6869931 (23)\ttotal: 11.7s\tremaining: 4m 3s\n",
      "46:\tlearn: 0.5801680\ttest: 0.6934409\tbest: 0.6869931 (23)\ttotal: 12s\tremaining: 4m 3s\n",
      "47:\tlearn: 0.5787209\ttest: 0.6942247\tbest: 0.6869931 (23)\ttotal: 12.3s\tremaining: 4m 3s\n",
      "48:\tlearn: 0.5775966\ttest: 0.6939972\tbest: 0.6869931 (23)\ttotal: 12.8s\tremaining: 4m 7s\n",
      "49:\tlearn: 0.5758012\ttest: 0.6937035\tbest: 0.6869931 (23)\ttotal: 13s\tremaining: 4m 7s\n",
      "50:\tlearn: 0.5746277\ttest: 0.6936208\tbest: 0.6869931 (23)\ttotal: 13.3s\tremaining: 4m 7s\n",
      "51:\tlearn: 0.5738762\ttest: 0.6941582\tbest: 0.6869931 (23)\ttotal: 13.6s\tremaining: 4m 7s\n",
      "52:\tlearn: 0.5726885\ttest: 0.6942057\tbest: 0.6869931 (23)\ttotal: 13.8s\tremaining: 4m 6s\n",
      "53:\tlearn: 0.5709959\ttest: 0.6933368\tbest: 0.6869931 (23)\ttotal: 14.1s\tremaining: 4m 6s\n",
      "54:\tlearn: 0.5698517\ttest: 0.6940449\tbest: 0.6869931 (23)\ttotal: 14.3s\tremaining: 4m 5s\n",
      "55:\tlearn: 0.5677137\ttest: 0.6936818\tbest: 0.6869931 (23)\ttotal: 14.5s\tremaining: 4m 4s\n",
      "56:\tlearn: 0.5659133\ttest: 0.6934175\tbest: 0.6869931 (23)\ttotal: 14.8s\tremaining: 4m 4s\n",
      "57:\tlearn: 0.5644903\ttest: 0.6938658\tbest: 0.6869931 (23)\ttotal: 15s\tremaining: 4m 3s\n",
      "58:\tlearn: 0.5623064\ttest: 0.6949277\tbest: 0.6869931 (23)\ttotal: 15.3s\tremaining: 4m 3s\n",
      "59:\tlearn: 0.5613933\ttest: 0.6953878\tbest: 0.6869931 (23)\ttotal: 15.5s\tremaining: 4m 3s\n",
      "60:\tlearn: 0.5600375\ttest: 0.6945692\tbest: 0.6869931 (23)\ttotal: 16s\tremaining: 4m 5s\n",
      "61:\tlearn: 0.5594325\ttest: 0.6944892\tbest: 0.6869931 (23)\ttotal: 16.2s\tremaining: 4m 4s\n",
      "62:\tlearn: 0.5577522\ttest: 0.6950187\tbest: 0.6869931 (23)\ttotal: 16.4s\tremaining: 4m 4s\n",
      "63:\tlearn: 0.5552285\ttest: 0.6960828\tbest: 0.6869931 (23)\ttotal: 16.7s\tremaining: 4m 3s\n",
      "64:\tlearn: 0.5531812\ttest: 0.6945091\tbest: 0.6869931 (23)\ttotal: 16.9s\tremaining: 4m 3s\n",
      "65:\tlearn: 0.5520706\ttest: 0.6941155\tbest: 0.6869931 (23)\ttotal: 17.2s\tremaining: 4m 2s\n",
      "66:\tlearn: 0.5513778\ttest: 0.6939314\tbest: 0.6869931 (23)\ttotal: 17.4s\tremaining: 4m 2s\n",
      "67:\tlearn: 0.5498218\ttest: 0.6941719\tbest: 0.6869931 (23)\ttotal: 17.7s\tremaining: 4m 1s\n",
      "68:\tlearn: 0.5486820\ttest: 0.6948469\tbest: 0.6869931 (23)\ttotal: 17.9s\tremaining: 4m 1s\n",
      "69:\tlearn: 0.5472940\ttest: 0.6945310\tbest: 0.6869931 (23)\ttotal: 18.1s\tremaining: 4m\n",
      "70:\tlearn: 0.5452653\ttest: 0.6953437\tbest: 0.6869931 (23)\ttotal: 18.4s\tremaining: 4m\n",
      "71:\tlearn: 0.5426814\ttest: 0.6941052\tbest: 0.6869931 (23)\ttotal: 18.6s\tremaining: 3m 59s\n",
      "72:\tlearn: 0.5404056\ttest: 0.6931837\tbest: 0.6869931 (23)\ttotal: 19.1s\tremaining: 4m 2s\n",
      "73:\tlearn: 0.5382292\ttest: 0.6931513\tbest: 0.6869931 (23)\ttotal: 19.3s\tremaining: 4m 1s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.686993091\n",
      "bestIteration = 23\n",
      "\n",
      "Shrink model to first 24 iterations.\n",
      "> batch#2/35\n",
      "Learning rate set to 0.029149\n",
      "0:\tlearn: 0.6905226\ttest: 0.6942470\tbest: 0.6942470 (0)\ttotal: 216ms\tremaining: 3m 35s\n",
      "1:\tlearn: 0.6880779\ttest: 0.6938276\tbest: 0.6938276 (1)\ttotal: 391ms\tremaining: 3m 14s\n",
      "2:\tlearn: 0.6852314\ttest: 0.6956215\tbest: 0.6938276 (1)\ttotal: 565ms\tremaining: 3m 7s\n",
      "3:\tlearn: 0.6831158\ttest: 0.6954262\tbest: 0.6938276 (1)\ttotal: 727ms\tremaining: 3m 1s\n",
      "4:\tlearn: 0.6787629\ttest: 0.6950101\tbest: 0.6938276 (1)\ttotal: 897ms\tremaining: 2m 58s\n",
      "5:\tlearn: 0.6748094\ttest: 0.6940353\tbest: 0.6938276 (1)\ttotal: 1.07s\tremaining: 2m 56s\n",
      "6:\tlearn: 0.6719734\ttest: 0.6941653\tbest: 0.6938276 (1)\ttotal: 1.24s\tremaining: 2m 55s\n",
      "7:\tlearn: 0.6685633\ttest: 0.6947909\tbest: 0.6938276 (1)\ttotal: 1.41s\tremaining: 2m 54s\n",
      "8:\tlearn: 0.6665881\ttest: 0.6959073\tbest: 0.6938276 (1)\ttotal: 1.59s\tremaining: 2m 54s\n",
      "9:\tlearn: 0.6641786\ttest: 0.6952307\tbest: 0.6938276 (1)\ttotal: 1.76s\tremaining: 2m 54s\n",
      "10:\tlearn: 0.6614814\ttest: 0.6956851\tbest: 0.6938276 (1)\ttotal: 1.95s\tremaining: 2m 55s\n",
      "11:\tlearn: 0.6580406\ttest: 0.6960067\tbest: 0.6938276 (1)\ttotal: 2.13s\tremaining: 2m 55s\n",
      "12:\tlearn: 0.6561826\ttest: 0.6960426\tbest: 0.6938276 (1)\ttotal: 2.31s\tremaining: 2m 55s\n",
      "13:\tlearn: 0.6533390\ttest: 0.6966322\tbest: 0.6938276 (1)\ttotal: 2.49s\tremaining: 2m 55s\n",
      "14:\tlearn: 0.6492982\ttest: 0.6962175\tbest: 0.6938276 (1)\ttotal: 2.66s\tremaining: 2m 54s\n",
      "15:\tlearn: 0.6473848\ttest: 0.6955810\tbest: 0.6938276 (1)\ttotal: 2.85s\tremaining: 2m 55s\n",
      "16:\tlearn: 0.6438471\ttest: 0.6954608\tbest: 0.6938276 (1)\ttotal: 3.04s\tremaining: 2m 55s\n",
      "17:\tlearn: 0.6405153\ttest: 0.6947632\tbest: 0.6938276 (1)\ttotal: 3.22s\tremaining: 2m 55s\n",
      "18:\tlearn: 0.6382332\ttest: 0.6956895\tbest: 0.6938276 (1)\ttotal: 3.41s\tremaining: 2m 56s\n",
      "19:\tlearn: 0.6347487\ttest: 0.6972036\tbest: 0.6938276 (1)\ttotal: 3.58s\tremaining: 2m 55s\n",
      "20:\tlearn: 0.6324885\ttest: 0.6977978\tbest: 0.6938276 (1)\ttotal: 3.77s\tremaining: 2m 55s\n",
      "21:\tlearn: 0.6309268\ttest: 0.6977815\tbest: 0.6938276 (1)\ttotal: 3.98s\tremaining: 2m 57s\n",
      "22:\tlearn: 0.6280863\ttest: 0.6983456\tbest: 0.6938276 (1)\ttotal: 4.21s\tremaining: 2m 59s\n",
      "23:\tlearn: 0.6257035\ttest: 0.6976395\tbest: 0.6938276 (1)\ttotal: 4.42s\tremaining: 2m 59s\n",
      "24:\tlearn: 0.6224238\ttest: 0.6969486\tbest: 0.6938276 (1)\ttotal: 4.64s\tremaining: 3m 1s\n",
      "25:\tlearn: 0.6198403\ttest: 0.6973889\tbest: 0.6938276 (1)\ttotal: 4.84s\tremaining: 3m 1s\n",
      "26:\tlearn: 0.6175210\ttest: 0.6978692\tbest: 0.6938276 (1)\ttotal: 5.05s\tremaining: 3m 2s\n",
      "27:\tlearn: 0.6166415\ttest: 0.6976159\tbest: 0.6938276 (1)\ttotal: 5.24s\tremaining: 3m 2s\n",
      "28:\tlearn: 0.6152147\ttest: 0.6984009\tbest: 0.6938276 (1)\ttotal: 5.45s\tremaining: 3m 2s\n",
      "29:\tlearn: 0.6127377\ttest: 0.6984494\tbest: 0.6938276 (1)\ttotal: 5.67s\tremaining: 3m 3s\n",
      "30:\tlearn: 0.6100557\ttest: 0.6997993\tbest: 0.6938276 (1)\ttotal: 5.89s\tremaining: 3m 4s\n",
      "31:\tlearn: 0.6088192\ttest: 0.7000246\tbest: 0.6938276 (1)\ttotal: 6.1s\tremaining: 3m 4s\n",
      "32:\tlearn: 0.6065029\ttest: 0.7005941\tbest: 0.6938276 (1)\ttotal: 6.29s\tremaining: 3m 4s\n",
      "33:\tlearn: 0.6041294\ttest: 0.7014315\tbest: 0.6938276 (1)\ttotal: 6.49s\tremaining: 3m 4s\n",
      "34:\tlearn: 0.6019005\ttest: 0.7020033\tbest: 0.6938276 (1)\ttotal: 6.67s\tremaining: 3m 3s\n",
      "35:\tlearn: 0.5998931\ttest: 0.7023727\tbest: 0.6938276 (1)\ttotal: 6.86s\tremaining: 3m 3s\n",
      "36:\tlearn: 0.5974010\ttest: 0.7019622\tbest: 0.6938276 (1)\ttotal: 7.05s\tremaining: 3m 3s\n",
      "37:\tlearn: 0.5959441\ttest: 0.7027870\tbest: 0.6938276 (1)\ttotal: 7.24s\tremaining: 3m 3s\n",
      "38:\tlearn: 0.5937259\ttest: 0.7022710\tbest: 0.6938276 (1)\ttotal: 7.43s\tremaining: 3m 3s\n",
      "39:\tlearn: 0.5923626\ttest: 0.7027316\tbest: 0.6938276 (1)\ttotal: 7.62s\tremaining: 3m 2s\n",
      "40:\tlearn: 0.5914333\ttest: 0.7025918\tbest: 0.6938276 (1)\ttotal: 7.82s\tremaining: 3m 2s\n",
      "41:\tlearn: 0.5897543\ttest: 0.7035477\tbest: 0.6938276 (1)\ttotal: 8.07s\tremaining: 3m 4s\n",
      "42:\tlearn: 0.5886087\ttest: 0.7039155\tbest: 0.6938276 (1)\ttotal: 8.27s\tremaining: 3m 4s\n",
      "43:\tlearn: 0.5869530\ttest: 0.7041316\tbest: 0.6938276 (1)\ttotal: 8.48s\tremaining: 3m 4s\n",
      "44:\tlearn: 0.5857072\ttest: 0.7039417\tbest: 0.6938276 (1)\ttotal: 8.7s\tremaining: 3m 4s\n",
      "45:\tlearn: 0.5839678\ttest: 0.7048375\tbest: 0.6938276 (1)\ttotal: 8.89s\tremaining: 3m 4s\n",
      "46:\tlearn: 0.5832979\ttest: 0.7047187\tbest: 0.6938276 (1)\ttotal: 9.08s\tremaining: 3m 4s\n",
      "47:\tlearn: 0.5815819\ttest: 0.7046680\tbest: 0.6938276 (1)\ttotal: 9.32s\tremaining: 3m 4s\n",
      "48:\tlearn: 0.5798989\ttest: 0.7043762\tbest: 0.6938276 (1)\ttotal: 9.53s\tremaining: 3m 5s\n",
      "49:\tlearn: 0.5788523\ttest: 0.7035529\tbest: 0.6938276 (1)\ttotal: 9.74s\tremaining: 3m 5s\n",
      "50:\tlearn: 0.5771448\ttest: 0.7049069\tbest: 0.6938276 (1)\ttotal: 9.96s\tremaining: 3m 5s\n",
      "51:\tlearn: 0.5755936\ttest: 0.7063604\tbest: 0.6938276 (1)\ttotal: 10.2s\tremaining: 3m 5s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.6938276014\n",
      "bestIteration = 1\n",
      "\n",
      "Shrink model to first 2 iterations.\n",
      "> batch#3/35\n"
     ]
    }
   ],
   "source": [
    "# директория с коллекцией респонсов\n",
    "PATH_TO_RESPONSES = 'L_games_collection'\n",
    "# директория с коллекцией признаков для игр (информация об игре)\n",
    "PATH_TO_FEATURES_GAMEINFO = r'D:\\\\features_gameinfo'\n",
    "# директория с коллекцией признаков для игр (командная статистика)\n",
    "PATH_TO_FEATURES_TEAM = r'D:\\\\features_team'\n",
    "# директория с коллекцией признаков для игр (статистика игроков)\n",
    "PATH_TO_FEATURES_PLAYER = r'D:\\\\features_player'\n",
    "\n",
    "# модель\n",
    "csgo_ml = CsgoOutcomePredictor()\n",
    "csgo_ml.fit(PATH_TO_RESPONSES, PATH_TO_FEATURES_GAMEINFO, PATH_TO_FEATURES_TEAM, PATH_TO_FEATURES_PLAYER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bc9092704b76bcd3825fbb7a05cb662b50152522ace34f313990aca7aedee1c7"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
